{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Label Mapping\n",
    "\n",
    "exclude: Support_Devices == 1\n",
    "\n",
    "| Condition           | Index |\n",
    "|---------------------|-------|\n",
    "| Cardiomegaly        | 0     |\n",
    "| Pleural Effusion    | 1     |\n",
    "| Edema               | 2     |\n",
    "| Fracture            | 3     |\n",
    "| Consolidation       | 4     |\n",
    "| Lung Opacity        | 4     |\n",
    "| Pneumonia           | 4     |\n",
    "| No Finding          | 5     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 07:59:14.150748: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 07:59:14.162782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-02 07:59:14.179255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-02 07:59:14.179278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-02 07:59:14.190158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-02 07:59:14.834614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Logical GPUs: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:10:40.775449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1762 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def setup_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(f\"Physical GPUs: {gpus}\")\n",
    "            print(f\"Logical GPUs: {logical_gpus}\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "setup_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(jpg_bytes):\n",
    "    image = tf.io.decode_jpeg(jpg_bytes)\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize image\n",
    "    return image.numpy()  # Convert to numpy array to ease GPU memory usage when not training directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged_Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung_Lesion</th>\n",
       "      <th>Lung_Opacity</th>\n",
       "      <th>No_Finding</th>\n",
       "      <th>Pleural_Effusion</th>\n",
       "      <th>Pleural_Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support_Devices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000052</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000103</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000125</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999832</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999849</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999880</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999924</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227827 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "study_id                                                                \n",
       "50000014           1            1             1              0      1   \n",
       "50000028           1            0             0              0      0   \n",
       "50000052           1            0             1              0      1   \n",
       "50000103           1            1             0              0      0   \n",
       "50000125           1            0             1              0      1   \n",
       "...              ...          ...           ...            ...    ...   \n",
       "59999832           1            0             1              0      1   \n",
       "59999849           1            1             1              0      1   \n",
       "59999880           1            0             0              0      0   \n",
       "59999888           1            0             1              0      1   \n",
       "59999924           1            0             0              0      0   \n",
       "\n",
       "          Enlarged_Cardiomediastinum  Fracture  Lung_Lesion  Lung_Opacity  \\\n",
       "study_id                                                                    \n",
       "50000014                           0         0            0             1   \n",
       "50000028                           0         0            1             0   \n",
       "50000052                           0         0            0             1   \n",
       "50000103                           0         0            0             1   \n",
       "50000125                           0         0            0             1   \n",
       "...                              ...       ...          ...           ...   \n",
       "59999832                           0         0            0             0   \n",
       "59999849                           1         0            0             1   \n",
       "59999880                           0         0            0             0   \n",
       "59999888                           0         0            1             0   \n",
       "59999924                           0         0            0             0   \n",
       "\n",
       "          No_Finding  Pleural_Effusion  Pleural_Other  Pneumonia  \\\n",
       "study_id                                                           \n",
       "50000014           0                 0              0          1   \n",
       "50000028           0                 0              0          0   \n",
       "50000052           0                 0              0          0   \n",
       "50000103           0                 1              0          0   \n",
       "50000125           0                 1              0          0   \n",
       "...              ...               ...            ...        ...   \n",
       "59999832           1                 1              0          1   \n",
       "59999849           0                 1              0          1   \n",
       "59999880           1                 0              0          0   \n",
       "59999888           0                 1              0          0   \n",
       "59999924           0                 0              0          0   \n",
       "\n",
       "          Pneumothorax  Support_Devices  \n",
       "study_id                                 \n",
       "50000014             0                0  \n",
       "50000028             0                0  \n",
       "50000052             1                1  \n",
       "50000103             0                0  \n",
       "50000125             1                1  \n",
       "...                ...              ...  \n",
       "59999832             0                1  \n",
       "59999849             1                1  \n",
       "59999880             0                0  \n",
       "59999888             0                0  \n",
       "59999924             0                0  \n",
       "\n",
       "[227827 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset//mimic_chexpert.csv')\n",
    "df.groupby(\"study_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "record_iterator = tf.compat.v1.python_io.tf_record_iterator(path='../../mimic-tf-record-withDicom.tfrecords')\n",
    "study = list()\n",
    "image = list()\n",
    "dicom = list()\n",
    "\n",
    "for string_record in tqdm(record_iterator, desc=\"Processing Records\"):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "\n",
    "    dicom.append(example.features.feature['dicom_id'].bytes_list.value[0].decode('utf-8'))\n",
    "    study.append(example.features.feature['study_id'].int64_list.value[0])\n",
    "    image.append(preprocess_image(example.features.feature['jpg_bytes'].bytes_list.value[0]) if example.features.feature['jpg_bytes'].bytes_list.value else None)\n",
    "\n",
    "df_image = pd.DataFrame({\"study_id\": study, \"image\": image, \"dicom_id\": dicom})\n",
    "df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./study_image_dicom.pkl', 'wb') as f:\n",
    "    pickle.dump({'study': study, 'image': image, 'dicom': dicom}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('j_arrays.h5', 'w') as f:\n",
    "    for i in trange(len(df_image)):\n",
    "        img = df_image.iloc[i][\"image\"]\n",
    "        study = np.zeros((1, 224, 1))\n",
    "        study[0][0][0] = df_image.iloc[i][\"study_id\"]\n",
    "        data = np.concatenate((img, study), axis=0)\n",
    "        f.create_dataset(f\"image_{i}\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_subject_id(df):\n",
    "    df = df[df['Support_Devices'] != 1]\n",
    "\n",
    "    unique_patient_ids = df['subject_id'].unique()\n",
    "    \n",
    "    train_ids, temp_ids = train_test_split(unique_patient_ids, test_size=0.2, random_state=42)\n",
    "    val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "    \n",
    "    train_df = df[df['subject_id'].isin(train_ids)]\n",
    "    val_df = df[df['subject_id'].isin(val_ids)]\n",
    "    test_df = df[df['subject_id'].isin(test_ids)]\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_subject_id(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, target_label, balance = False):\n",
    "    df = df[df['Support_Devices']!=1]\n",
    "    \n",
    "    \n",
    "    df['Label_0'] = df['Cardiomegaly'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['Label_1'] = df['Pleural_Effusion'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['Label_2'] = df['Edema'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['Label_3'] = df['Fracture'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['Label_4'] = df[['Consolidation', 'Lung_Opacity', 'Pneumonia']].max(axis=1).apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['Label_5'] = df['No_Finding'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    \n",
    "    # Group by study_id and aggregate to get the count of target label per study\n",
    "    df_grouped = df.groupby('study_id').agg(\n",
    "        target_label_count=(target_label, 'sum')\n",
    "    ).reset_index()\n",
    "    #print(len(df_grouped), len(df))\n",
    "    # Separate studies with target label 1 and 0\n",
    "    positive_studies = df_grouped[df_grouped['target_label_count'] == 1]['study_id']\n",
    "    negative_studies = df_grouped[df_grouped['target_label_count'] == 0]['study_id']\n",
    "    \n",
    "    # Ensure equal number of positive and negative samples by downsampling\n",
    "    min_count = min(len(positive_studies), len(negative_studies))\n",
    "    if balance:\n",
    "        positive_studies_sampled = positive_studies.sample(min_count, random_state=42)\n",
    "        negative_studies_sampled = negative_studies.sample(min_count, random_state=42)\n",
    "    else:\n",
    "        positive_studies_sampled = positive_studies\n",
    "        negative_studies_sampled = negative_studies\n",
    "        \n",
    "    #print(len(positive_studies_sampled), len(negative_studies_sampled))\n",
    "    \n",
    "    # Combine positive and negative samples\n",
    "    balanced_studies = pd.concat([positive_studies_sampled, negative_studies_sampled])\n",
    "    \n",
    "    # Filter original dataframe for these studies\n",
    "    df_balanced = df[df['study_id'].isin(balanced_studies)]\n",
    "    \n",
    "    \n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    balance_train_df = create_dataset(train_df, f'Label_{i}', True)\n",
    "    balance_train_df[[\"study_id\", f'Label_{i}']].to_csv(f'j_train_TEST_Label_{i}.csv', index=False)\n",
    "    \n",
    "    original_val_df = create_dataset(val_df, f'Label_{i}', False)\n",
    "    original_val_df[[\"study_id\", f'Label_{i}']].to_csv(f'j_val_Label_{i}.csv', index=False)\n",
    "    \n",
    "    original_test_df = create_dataset(test_df, f'Label_{i}', False)\n",
    "    original_test_df[[\"study_id\", f'Label_{i}']].to_csv(f'j_pred_Label_{i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ywy",
   "language": "python",
   "name": "env_ywy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
